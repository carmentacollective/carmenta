{
  "timestamp": "2025-12-27T03:33:29.094Z",
  "version": "2.0.0",
  "overallScore": 87,
  "queryCount": 20,
  "byCategory": [
    {
      "category": "real-world",
      "avgScore": 87,
      "queryCount": 20,
      "lowestScoring": [
        {
          "queryId": "real-008-slow-query",
          "score": 79
        },
        {
          "queryId": "real-001-career-path",
          "score": 80
        },
        {
          "queryId": "real-016-multi-tenant",
          "score": 80
        }
      ]
    }
  ],
  "byDimension": [
    {
      "dimension": "clarity",
      "avgScore": 92
    },
    {
      "dimension": "actionability",
      "avgScore": 86
    },
    {
      "dimension": "completeness",
      "avgScore": 86
    },
    {
      "dimension": "accuracy",
      "avgScore": 84
    }
  ],
  "lowestScoring": [
    {
      "queryId": "real-008-slow-query",
      "score": 79,
      "category": "real-world"
    },
    {
      "queryId": "real-001-career-path",
      "score": 80,
      "category": "real-world"
    },
    {
      "queryId": "real-016-multi-tenant",
      "score": 80,
      "category": "real-world"
    },
    {
      "queryId": "real-015-search",
      "score": 81,
      "category": "real-world"
    },
    {
      "queryId": "real-005-hydration-error",
      "score": 82,
      "category": "real-world"
    },
    {
      "queryId": "real-010-migration-estimate",
      "score": 82,
      "category": "real-world"
    },
    {
      "queryId": "real-014-rate-limiting",
      "score": 85,
      "category": "real-world"
    },
    {
      "queryId": "real-006-memory-leak",
      "score": 86,
      "category": "real-world"
    },
    {
      "queryId": "real-013-notification-system",
      "score": 86,
      "category": "real-world"
    },
    {
      "queryId": "real-003-burnout",
      "score": 89,
      "category": "real-world"
    }
  ],
  "queryResults": [
    {
      "queryId": "real-001-career-path",
      "query": {
        "id": "real-001-career-path",
        "query": "I'm a mid-level frontend developer (3 years). Should I specialize in AI/ML or go deeper into frontend architecture? What factors should I consider?",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests providing career framework without overprescribing.",
        "primaryDimensions": ["actionability", "completeness", "clarity"],
        "tags": ["career", "decision-making"],
        "source": "custom"
      },
      "response": "Let's break this down structurally so you can weigh what matters most to your situation.## Key Decision Factors\n\n**Risk tolerance:** AI/ML is higher reward but less certain. The field shifts monthly. Frontend architecture offers a proven path with predictable outcomes.\n\n**Learning preference:** Do you prefer building on what you know (architecture) or learning adjacent domains that feel uncomfortable at first (AI/ML requires genuine math and systems thinking beyond web dev)?\n\n**Market timing:** AI is peaking in hype right now. That means opportunity but also noise. Frontend architecture demand is countercyclical—companies always need someone to untangle their React spaghetti.\n\n**The hybrid option:** You don't have to choose exclusively. The most valuable position might be \"frontend architect who deeply understands AI product constraints.\" Build AI-powered interfaces while understanding system design, performance, and DX at depth. This takes longer but compounds both skill sets.\n\n**Austin context:** Strong markets for both. AI hiring is hot across venture-backed startups. Enterprise companies (Indeed, Oracle, Tesla) need frontend architecture expertise. You're in a good location for either path.\n\n## Questions That Clarify\n\n- Are you energized or drained by rapidly changing technical landscapes?\n- Do you want to stay close to UI/UX or move toward infrastructure/systems?\n- What does your network look like? Leverage matters more than raw skill.\n- Financial runway: can you afford 12-18 months of harder learning before AI roles materialize?\n\nWhat pulls you more strongly right now—the architectural puzzle-solving or the frontier excitement of AI?",
      "latencyMs": 33188,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 74,
          "reasoning": "Gives usable decision factors and reflective questions, but lacks concrete next steps (e.g., trial plan, timelines, specific learning paths, ways to test-fit AI/ML vs architecture) to make an immediate decision."
        },
        {
          "dimension": "completeness",
          "score": 78,
          "reasoning": "Addresses the core choice and lists several relevant factors, including a hybrid option. However, it misses some important considerations like role availability for a frontend-to-ML transition, specific skill gaps and how to bridge them, portfolio strategy, compensation/leveling implications, and clearer criteria for deciding."
        },
        {
          "dimension": "clarity",
          "score": 88,
          "reasoning": "Well-structured with headings and bullets, easy to scan and understand. Minor clarity issue: includes 'Austin context' without it being in the query, which can distract from the general guidance."
        }
      ],
      "overallScore": 80,
      "timestamp": "2025-12-27T03:22:19.924Z"
    },
    {
      "queryId": "real-002-learning-path",
      "query": {
        "id": "real-002-learning-path",
        "query": "I want to learn databases for architectural decisions (not become a DBA). Create a focused learning path for 2-3 months part-time.",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests creating achievable, scoped learning plan.",
        "primaryDimensions": ["actionability", "completeness", "clarity"],
        "tags": ["learning", "databases"],
        "source": "custom"
      },
      "response": "## Focused Database Architecture Learning Path\n**Goal: Make informed architectural decisions in 2-3 months part-time (6-8 hours/week)**\n\n### Phase 1: Core Concepts (Weeks 1-3)\n\n**Foundation: Understanding the trade-off space**\n\nStart with *Designing Data-Intensive Applications* by Martin Kleppmann (chapters 1-3, 5-9). This is the gold standard for architectural understanding. Focus on:\n- Data models and query languages\n- Storage and retrieval fundamentals\n- Replication, partitioning, transactions\n- The trouble with distributed systems\n\nSkip: Chapter 4 (encoding) and 10-12 on initial pass. You can return to these later if specific needs emerge.\n\n**Hands-on:**\n- Set up PostgreSQL locally\n- Model a real domain you know (e.g., e-commerce, content platform)\n- Write queries that demonstrate different access patterns\n- Observe query plans to see how data structure affects performance\n\n**Key questions to answer:**\n- What are the fundamental trade-offs between consistency, availability, and partition tolerance?\n- How do ACID guarantees affect architectural choices?\n- What's the cost difference between reads and writes in different systems?\n\n### Phase 2: Paradigm Exploration (Weeks 4-7)\n\n**Goal: Hands-on experience with different database types to understand when each fits**\n\nBuild the same simple application (blog with comments, search, user sessions, analytics) using different databases:\n\n**Week 4: Document Database (MongoDB)**\n- Model denormalized documents vs normalized relations\n- Understand schema flexibility trade-offs\n- Observe when embedding vs referencing makes sense\n\n**Week 5: Key-Value + Cache (Redis)**\n- Implement session storage and caching layer\n- Understand TTLs and eviction policies\n- Learn when ephemeral data shapes architecture\n\n**Week 6: Columnar/Analytics (DuckDB)**\n- Query the same data optimized for analytics\n- Understand why column stores excel at aggregations\n- See the OLTP vs OLAP distinction in practice\n\n**Week 7: Graph (Neo4j community edition)**\n- Model relationships-heavy features (social connections, recommendations)\n- Write Cypher queries vs equivalent SQL joins\n- Understand when relationship traversal matters\n\n**Outcome: A comparison matrix you've built yourself**\n- Query patterns each excels at\n- Scaling characteristics\n- Operational complexity\n- Cost profile (compute, storage, ops)\n\n### Phase 3: Architectural Patterns (Weeks 8-10)\n\n**Read and synthesize:**\n- AWS Well-Architected Framework (Data section)\n- Google Cloud Architecture Center (Database decision trees)\n- Martin Fowler's articles on polyglot persistence and CQRS\n\n**Case studies to analyze:**\n- Uber's move from PostgreSQL to MySQL to custom solutions\n- Discord's migration from MongoDB to Cassandra for messages\n- Figma's scaling challenges with PostgreSQL/RDS\n- Notion's Postgres-based architecture\n\nFor each case study, document:\n- What growth pattern forced the decision\n- Trade-offs they explicitly made\n- What they gave up and what they gained\n- What they'd do differently\n\n**Pattern recognition:**\n- Read-heavy vs write-heavy workloads\n- Consistency requirements by feature\n- Multi-region strategies\n- Cost optimization patterns\n\n### Phase 4: Decision Framework (Weeks 11-12)\n\n**Build your architectural decision framework:**\n\nCreate a decision matrix template that captures:\n- Access patterns (read/write ratio, query complexity)\n- Scale requirements (data volume, request volume, growth rate)\n- Consistency needs (strong vs eventual by feature)\n- Operational constraints (team expertise, budget, SLAs)\n- Integration requirements (existing stack, tooling)\n\n**Practice on real scenarios:**\n- Take 3-5 real architectural decisions from companies (blog posts, conference talks)\n- Apply your framework\n- Compare your recommendation to what they chose\n- Understand the gaps (often organizational constraints you couldn't see)\n\n**Capstone: Design a realistic system**\nChoose a complex domain (e.g., food delivery platform, video streaming service, financial trading platform). Design the complete data architecture:\n- What databases for which subsystems\n- How they interact\n- Where the complexity lives\n- What breaks first as you scale\n- What it costs\n\n### Resources by Priority\n\n**Essential:**\n- *Designing Data-Intensive Applications* (Kleppmann)\n- Hands-on time with PostgreSQL, MongoDB, Redis (3-4 hours/week)\n\n**High value:**\n- Database vendor architecture docs (PostgreSQL, MongoDB, DynamoDB)\n- Conference talks from QCon, Strange Loop on database architecture\n- Company engineering blogs (Uber, Airbnb, Netflix engineering)\n\n**Optional depth:**\n- CMU Database Systems course (YouTube, Andy Pavlo)\n- Papers: Dynamo, Bigtable, Spanner (if distributed systems interest you)\n\n### Weekly Time Breakdown (7 hours)\n\n- **Reading/watching:** 2 hours\n- **Hands-on implementation:** 3 hours  \n- **Writing synthesis/notes:** 1 hour\n- **Case study analysis:** 1 hour\n\n### Success Metrics\n\nYou're ready to make architectural database decisions when you can:\n\n1. Given a feature spec, identify data access patterns and map them to appropriate database types\n2. Articulate the specific trade-offs between options (not just \"it depends\")\n3. Estimate when you'll hit scaling limits with different approaches\n4. Explain your decision in terms of business constraints, not just technical preferences\n5. Know what you don't know and what questions to ask DBAs/specialists\n\nThis path emphasizes understanding over mastery. You're building the judgment to choose well and collaborate effectively, not to tune indexes or optimize replication lag. That distinction keeps it achievable in 2-3 months while delivering real architectural capability.\n\nWhat aspects of this feel most relevant to where you're headed? We can adjust the emphasis based on whether you're more focused on startups, scale-ups, or enterprise contexts.",
      "latencyMs": 46669,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 88,
          "reasoning": "Provides a week-by-week structure, concrete resources, suggested hands-on projects, and a time breakdown. Minor gaps: specific links/case-study sources aren’t provided, and hands-on tasks could be more prescriptive (e.g., exact exercises, datasets, deliverables) to be fully plug-and-play."
        },
        {
          "dimension": "completeness",
          "score": 91,
          "reasoning": "Directly addresses a 2–3 month part-time learning path aimed at architectural decision-making (not DBA work), covering fundamentals, multiple DB paradigms, patterns, and a decision framework plus success metrics. Small omission: less emphasis on schema design/normalization trade-offs and practical cloud-managed DB selection (RDS/Cloud SQL/DynamoDB) beyond general references."
        },
        {
          "dimension": "clarity",
          "score": 93,
          "reasoning": "Very well organized into phases with weeks, goals, outcomes, and bullet points. Easy to scan and follow, with clear separation between essential vs optional material. Slightly dense in places (many resources/case studies) but overall highly readable."
        }
      ],
      "overallScore": 91,
      "timestamp": "2025-12-27T03:23:11.258Z"
    },
    {
      "queryId": "real-003-burnout",
      "query": {
        "id": "real-003-burnout",
        "query": "I've worked 60+ hour weeks for 6 months. I'm exhausted but we're behind on a critical project. How do I handle this?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests balanced work/life advice with empathy.",
        "primaryDimensions": ["actionability", "clarity"],
        "tags": ["career", "burnout", "wellbeing"],
        "source": "custom"
      },
      "response": "Six months at that pace has almost certainly degraded your effectiveness more than you realize. Exhaustion compounds—what took 60 hours in month one likely takes 70+ now for the same output, with more errors and rework.\n\nThe hard truth: continuing this pace won't save the project. It increases the risk of catastrophic mistakes, burnout-driven departure (leaving the team in worse shape), or collapse right when you're needed most.\n\n**Immediate actions:**\n\n**Protect recovery time now.** Even while behind, build in actual rest—one full day off per week minimum, hard stop times most evenings. Sleep deprivation alone tanks cognitive function 20-30%. You're likely working more hours to produce less.\n\n**Quantify the real situation.** What does \"behind\" mean? Behind an arbitrary deadline, or behind a truly immovable constraint? Most \"critical\" deadlines have more flexibility than assumed when someone's about to break. Get specific about consequences of different timelines.\n\n**Have the conversation.** With your manager or whoever owns this: \"I've sustained 60+ hour weeks for 6 months. That pace is no longer sustainable and is likely reducing my effectiveness. I need us to either: extend the timeline, reduce scope, or bring in additional resources. Which makes most sense given actual constraints?\"\n\nThis isn't asking permission to rest—it's presenting reality. Unsustainable means exactly that: it cannot be sustained. The only question is whether we acknowledge it and adjust deliberately, or wait for a forced adjustment (worse mistakes, illness, quitting).\n\n**Scope ruthlessly.** What 20% of remaining work delivers 80% of value? Behind schedule is exactly when we need to cut features, not heroics. Ship something good rather than collapsing before shipping something perfect.\n\nWhat's the actual deadline, and what happens if it moves? That clarity changes everything about how we navigate this.",
      "latencyMs": 24603,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 86,
          "reasoning": "Gives concrete next steps (set rest boundaries, quantify the deadline/constraints, have a specific conversation with manager using suggested wording, cut scope). However, it lacks more operational details (how to renegotiate scope/timeline, prioritization process, escalation paths, or contingencies if management refuses), so some additional work/clarification is needed."
        },
        {
          "dimension": "clarity",
          "score": 92,
          "reasoning": "Well-structured with a clear framing and a labeled \"Immediate actions\" section. The recommendations are easy to follow, logically ordered, and written in plain language with a helpful example script."
        }
      ],
      "overallScore": 89,
      "timestamp": "2025-12-27T03:23:39.720Z"
    },
    {
      "queryId": "real-004-negotiation",
      "query": {
        "id": "real-004-negotiation",
        "query": "Job offer for $180K, current salary $150K. They know my current salary. How should I negotiate for more?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests practical negotiation advice.",
        "primaryDimensions": ["actionability", "clarity"],
        "tags": ["career", "negotiation"],
        "source": "custom"
      },
      "response": "**The Anchor Problem**\n\nThey anchored you at $150K. The $180K offer looks generous (20% raise), making it psychologically harder to push back. But the offer isn't based on what *you're worth to them*—it's based on what you cost now plus a premium to move you.\n\n**Reframe the Conversation**\n\nMove away from your current salary entirely. Focus on:\n\n**Market value for the role**: \"I've researched similar positions in Austin with this scope, and the range is $190-210K. Where does this role fall in your band?\"\n\n**Total compensation**: If they're stuck on base, negotiate signing bonus ($20-30K), year-one bonus guarantee, equity refresh, or earlier review cycle.\n\n**What you bring**: Be specific. \"I'm bringing X expertise that typically commands Y. Similar roles at [comparable company] are paying Z.\" Use competing offers if you have them, even if you wouldn't take them.\n\n**Specific Script**\n\n\"I'm excited about this role. The $180K is a strong offer, and I appreciate it. That said, given the scope of what I'd be taking on and market rates for someone with my background in [specific expertise], I was expecting something closer to $200K. Is there flexibility in the base, or should we look at the total package?\"\n\n**The Number**\n\nAsk for $195-200K. Expect to land at $185-190K. If they won't move on base, get a $15K signing bonus or guaranteed first-year bonus.\n\n**What Not to Do**\n\nDon't say \"I need more\" or \"I was hoping for more.\" Say what you're worth and why, then let silence work for you.\n\nWhat's the role, and what's your leverage (other offers, specialized skills, their urgency)?",
      "latencyMs": 21339,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 88,
          "reasoning": "Provides concrete negotiation tactics (reframe to market value/total comp), specific numbers to ask for, fallback options (sign-on, bonus guarantee, review cycle), and a usable script. Minor gaps: assumes a location/range without verifying, and suggests using competing offers even if you wouldn’t take them (could be risky/ethically questionable), so the user may need to tailor details."
        },
        {
          "dimension": "clarity",
          "score": 92,
          "reasoning": "Well-structured with clear headings, bullets, and a straightforward script. The logic flows from problem framing to tactics to exact ask and pitfalls. Very easy to follow and apply with minimal interpretation."
        }
      ],
      "overallScore": 90,
      "timestamp": "2025-12-27T03:24:05.381Z"
    },
    {
      "queryId": "real-005-hydration-error",
      "query": {
        "id": "real-005-hydration-error",
        "query": "My Next.js app works in dev but production gives \"Hydration failed because initial UI doesn't match server render.\" Intermittent, can't reproduce locally. How to debug?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests systematic debugging for common Next.js issue.",
        "primaryDimensions": ["accuracy", "actionability", "completeness"],
        "tags": ["debugging", "nextjs", "hydration"],
        "source": "custom"
      },
      "response": "Hydration mismatches in production but not dev usually point to environment-specific rendering or timing issues. Here's how to hunt it down:\n\n## Immediate Debug Steps\n\n**1. Enable detailed hydration errors** (React 18.2+)\n```javascript\n// next.config.js\nmodule.exports = {\n  reactStrictMode: true,\n  experimental: {\n    strictNextHead: true, // Catches <Head> issues\n  }\n}\n```\n\n**2. Add strategic console logs**\n```javascript\n// Wrap suspect components\nuseEffect(() => {\n  console.log('Client hydrated:', { \n    timestamp: new Date().toISOString(),\n    userAgent: navigator.userAgent \n  });\n}, []);\n\n// On server\nconsole.log('Server render:', {\n  timestamp: new Date().toISOString(),\n  env: process.env.NODE_ENV\n});\n```\n\n**3. Inspect the HTML mismatch**\nIn production, before React hydrates:\n- Open DevTools → Network → Find the document\n- Copy the initial HTML\n- Let the page hydrate and error\n- Compare DOM tree to saved HTML\n- React usually logs which element mismatched\n\n## Common Culprits\n\n**Timing-dependent values**\n```javascript\n// ❌ Different on server vs client\n<div>{new Date().toLocaleString()}</div>\n<div>{Math.random()}</div>\n\n// ✅ Suppress or defer to client\n<div suppressHydrationWarning>{new Date().toLocaleString()}</div>\n\n// Or client-only render\nconst [mounted, setMounted] = useState(false);\nuseEffect(() => setMounted(true), []);\nif (!mounted) return null;\n```\n\n**Browser-only APIs**\n```javascript\n// ❌ window undefined on server\nconst width = window.innerWidth;\n\n// ✅ Guard it\nconst width = typeof window !== 'undefined' ? window.innerWidth : 0;\n\n// Or use state\nconst [width, setWidth] = useState(0);\nuseEffect(() => setWidth(window.innerWidth), []);\n```\n\n**Third-party scripts**\nBrowser extensions, analytics, chat widgets can inject DOM before hydration. Check:\n```javascript\n// _document.js - move scripts to afterInteractive or lazyOnload\n<Script \n  src=\"https://...\"\n  strategy=\"lazyOnload\" // Not \"beforeInteractive\"\n/>\n```\n\n**Invalid HTML nesting**\n```javascript\n// ❌ <p> can't contain <div>\n<p><div>text</div></p>\n\n// ❌ <a> can't contain <a>\n<Link href=\"/\"><a><Link href=\"/nested\"><a>...</a></Link></a></Link>\n```\n\n## Production-Specific Issues\n\n**Environment variables**\n```javascript\n// Check if different values in prod\nconsole.log({\n  NODE_ENV: process.env.NODE_ENV,\n  NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL\n});\n```\n\n**Data fetching timing**\n```javascript\n// If using getServerSideProps, ensure data is identical\nexport async function getServerSideProps(context) {\n  // Log what's fetched\n  console.log('SSR data fetch:', context.req.headers);\n  \n  // Cache headers affecting data?\n  // Race conditions with external APIs?\n}\n```\n\n**Caching/CDN issues**\n- Old HTML cached with new JS bundle\n- Clear CDN cache, redeploy\n- Check if Cache-Control headers are too aggressive\n\n## Systematic Elimination\n\nSince it's intermittent, binary search through your components:\n\n1. **Add suppressHydrationWarning** to half the page\n2. Deploy, see if error persists\n3. Narrow down which section causes it\n4. Repeat until you find the specific component\n\n```javascript\n// Temporarily wrap sections\n<div suppressHydrationWarning>\n  <SuspectComponent />\n</div>\n```\n\n## Monitoring in Production\n\nAdd error boundary to catch and report the exact mismatch:\n```javascript\n// pages/_app.js\nuseEffect(() => {\n  const handleError = (event) => {\n    if (event.message.includes('Hydration failed')) {\n      // Log to your error tracking\n      console.error('Hydration error details:', {\n        message: event.message,\n        html: document.documentElement.outerHTML.slice(0, 1000),\n        userAgent: navigator.userAgent,\n        timestamp: Date.now()\n      });\n    }\n  };\n  \n  window.addEventListener('error', handleError);\n  return () => window.removeEventListener('error', handleError);\n}, []);\n```\n\nWhat does your component tree look like around the error? Any date formatting, conditional rendering, or third-party integrations in play?",
      "latencyMs": 34560,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 78,
          "reasoning": "Most guidance is correct (common mismatch causes like Date/Math.random, window access, third‑party DOM injection, invalid HTML, CDN caching). However a few items are misleading: setting reactStrictMode/strictNextHead doesn’t really “enable detailed hydration errors,” suppressHydrationWarning hides symptoms rather than debugging, and relying on window 'error' events may not consistently capture React hydration warnings/errors (often logged via console.error). Minor Next.js specifics (app router/client components, dynamic import ssr:false) are not addressed."
        },
        {
          "dimension": "actionability",
          "score": 85,
          "reasoning": "Provides concrete steps (inspect initial HTML, add targeted logs, list of culprits with code snippets, check scripts strategies, review caching/CDN), plus a systematic narrowing approach. Some steps would need refinement (better instrumentation than suppressHydrationWarning, more precise Next.js config/logging locations), but overall a user can act on it."
        },
        {
          "dimension": "completeness",
          "score": 82,
          "reasoning": "Covers a broad set of likely causes and offers multiple debugging angles (DOM diffing, env vars, data fetching, caching). Gaps: doesn’t discuss App Router nuances ('use client', server/client component boundaries), dynamic import with ssr:false as a diagnostic, source maps/production logging setup, React strict mode differences between dev/prod, or how to reliably capture hydration stack traces in production."
        }
      ],
      "overallScore": 82,
      "timestamp": "2025-12-27T03:24:46.992Z"
    },
    {
      "queryId": "real-006-memory-leak",
      "query": {
        "id": "real-006-memory-leak",
        "query": "Node.js server memory keeps growing until crash. How do I find and fix the memory leak?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests memory debugging methodology.",
        "primaryDimensions": ["accuracy", "actionability", "completeness"],
        "tags": ["debugging", "nodejs", "memory"],
        "source": "custom"
      },
      "response": "Memory leaks in Node.js typically come from a few patterns. Here's how to hunt them down:\n\n## Confirm It's Actually Leaking\n\nMonitor heap usage over time:\n\n```javascript\n// Add to your server\nsetInterval(() => {\n  const used = process.memoryUsage();\n  console.log({\n    rss: `${Math.round(used.rss / 1024 / 1024)}MB`,\n    heapUsed: `${Math.round(used.heapUsed / 1024 / 1024)}MB`,\n    heapTotal: `${Math.round(used.heapTotal / 1024 / 1024)}MB`\n  });\n}, 30000);\n```\n\nIf `heapUsed` climbs steadily without leveling off, you've got a leak.\n\n## Capture Heap Snapshots\n\nUse Chrome DevTools to compare snapshots and find what's growing:\n\n```bash\n# Start your server with inspect flag\nnode --inspect server.js\n\n# In Chrome, visit chrome://inspect\n# Click \"inspect\" on your process\n# Go to Memory tab → Take Heap Snapshot\n```\n\nTake one snapshot at startup, another after load, compare them. Look for objects with unexpected retention counts or size growth.\n\n## The Usual Suspects\n\n**Event listeners piling up:**\n```javascript\n// Bad - leaks on every request\napp.get('/data', (req, res) => {\n  emitter.on('update', handler); // Never removed\n});\n\n// Good\napp.get('/data', (req, res) => {\n  const handler = () => { /* ... */ };\n  emitter.once('update', handler); // Auto-removes\n  // or: emitter.removeListener('update', handler);\n});\n```\n\n**Global caches without bounds:**\n```javascript\n// Bad - grows forever\nconst cache = {};\napp.get('/user/:id', (req, res) => {\n  cache[req.params.id] = userData; // Never pruned\n});\n\n// Good - use LRU cache\nconst LRU = require('lru-cache');\nconst cache = new LRU({ max: 500 });\n```\n\n**Closures holding references:**\n```javascript\n// Bad - closure keeps entire req/res in memory\napp.get('/data', (req, res) => {\n  fetchData().then(data => {\n    setTimeout(() => {\n      // This closure captures req/res unnecessarily\n      console.log(req.url); \n    }, 60000);\n  });\n});\n\n// Good - extract only what you need\napp.get('/data', (req, res) => {\n  const url = req.url;\n  fetchData().then(data => {\n    setTimeout(() => {\n      console.log(url);\n    }, 60000);\n  });\n});\n```\n\n**Forgotten timers:**\n```javascript\n// Bad - timer outlives the object\nclass Handler {\n  constructor() {\n    setInterval(() => {\n      this.doWork();\n    }, 1000); // Never cleared\n  }\n}\n\n// Good - clean up\nclass Handler {\n  constructor() {\n    this.timer = setInterval(() => {\n      this.doWork();\n    }, 1000);\n  }\n  destroy() {\n    clearInterval(this.timer);\n  }\n}\n```\n\n## Production-Ready Tools\n\n**Clinic.js** gives you flamegraphs and heap analysis:\n```bash\nnpm install -g clinic\nclinic doctor -- node server.js\n# Run your load test\n# Ctrl+C to stop and generate report\n```\n\n**Heapdump** for on-demand snapshots:\n```javascript\nconst heapdump = require('heapdump');\n// Write snapshot on demand (trigger via endpoint or signal)\nheapdump.writeSnapshot(`./heap-${Date.now()}.heapsnapshot`);\n```\n\n**memwatch-next** alerts on leaks automatically:\n```javascript\nconst memwatch = require('@airbnb/node-memwatch');\nmemwatch.on('leak', (info) => {\n  console.error('Memory leak detected:', info);\n});\n```\n\n## Quick Win: Check These First\n\n1. **Streams not closed** - Always `.destroy()` or handle errors\n2. **Database connections** - Use connection pooling, close connections\n3. **Large arrays growing** - Switch to streams for big data\n4. **Session stores** - Configure expiration\n5. **Promises without error handlers** - Can hold references indefinitely\n\nWhat kind of workload is your server handling? That'll narrow down where to look first.",
      "latencyMs": 27195,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 82,
          "reasoning": "Largely correct guidance (heap snapshots via inspector, common leak patterns like unbounded caches/listeners/timers, Clinic.js/heapdump). Minor issues: memwatch-next/@airbnb node-memwatch is deprecated/unreliable in many setups; a few items are oversimplified (heapUsed growth can be GC/fragmentation, “promises without error handlers” isn’t a typical direct leak cause). Examples are broadly valid but not all are true leaks vs intentional retention."
        },
        {
          "dimension": "actionability",
          "score": 91,
          "reasoning": "Provides clear, step-by-step next actions: add memory logging, run node with --inspect, take/compare heap snapshots, and concrete code patterns to fix. Includes specific commands for Clinic and sample heapdump usage. A user can follow this immediately with minimal extra context."
        },
        {
          "dimension": "completeness",
          "score": 86,
          "reasoning": "Covers major parts of finding and fixing Node.js memory leaks: verification, heap snapshot workflow, typical sources, and tooling. Minor gaps: doesn’t mention allocation sampling/timeline in DevTools, heap profiles, using --trace-gc/GC logs to distinguish leak vs churn, native (C++) leaks, container memory limits, or guidance on reproducing under load and comparing snapshots systematically."
        }
      ],
      "overallScore": 86,
      "timestamp": "2025-12-27T03:25:20.465Z"
    },
    {
      "queryId": "real-007-cors-error",
      "query": {
        "id": "real-007-cors-error",
        "query": "CORS errors calling my API from React, only in production. API has CORS configured. What's wrong?",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests CORS troubleshooting knowledge.",
        "primaryDimensions": ["accuracy", "actionability"],
        "tags": ["debugging", "cors", "deployment"],
        "source": "custom"
      },
      "response": "The issue is almost always one of these:\n\n**1. Origin mismatch**\nYour API's CORS config likely specifies allowed origins. In dev, you're probably calling from `localhost:3000` to `localhost:8000`. In production, you might be calling from `yourdomain.com` to `api.yourdomain.com`, but your CORS config still only allows localhost.\n\nCheck your API's CORS configuration - what origins does it allow? Does it include your production frontend URL exactly as the browser sees it (including protocol)?\n\n**2. Dev proxy hiding the problem**\nIf you're using Create React App or Vite with a proxy configuration, dev requests go through the proxy to the same origin, bypassing CORS entirely. Production has no proxy, so CORS suddenly matters.\n\n**3. Protocol mismatch**\nFrontend on `https://yourdomain.com` calling `http://api.yourdomain.com` will fail. Mixed content policies block it before CORS even gets involved.\n\n**4. Credentials without explicit origin**\nIf you're sending `credentials: 'include'` or `withCredentials: true`, the API can't use `Access-Control-Allow-Origin: *`. It must specify the exact origin and include `Access-Control-Allow-Credentials: true`.\n\n**Quick diagnostic:**\nOpen browser DevTools → Network tab → Find the failed request → Check:\n- What's the **request Origin header**?\n- Is there a preflight OPTIONS request? Did it succeed?\n- What **Access-Control-Allow-Origin** does the response have?\n\nTell me what you see in those headers and I can pinpoint exactly what's misconfigured.",
      "latencyMs": 20347,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 93,
          "reasoning": "The response correctly identifies the most common real-world causes of CORS issues that appear only in production (origin allowlist mismatch, dev proxy masking CORS, mixed-content http/https mismatch, and credentials requiring non-wildcard ACAO + ACAC). The diagnostic guidance about checking Origin, preflight OPTIONS, and Access-Control-Allow-* headers is correct. It omits some less-common production-specific culprits (CDN/proxy stripping headers, cached preflight, redirects changing origin), but nothing stated is wrong."
        },
        {
          "dimension": "actionability",
          "score": 91,
          "reasoning": "Provides clear, concrete next steps: verify exact allowed origins including scheme, check whether a dev proxy hid CORS, ensure https-to-https, handle credentials properly, and inspect specific headers in DevTools (including preflight). A user can immediately follow these steps; only minor additional context (their specific stack/config) would be needed to apply fixes."
        }
      ],
      "overallScore": 92,
      "timestamp": "2025-12-27T03:25:45.087Z"
    },
    {
      "queryId": "real-008-slow-query",
      "query": {
        "id": "real-008-slow-query",
        "query": "This PostgreSQL query takes 30 seconds on 10M rows. How to optimize?\n\n```sql\nSELECT u.*, COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nWHERE u.created_at > '2024-01-01'\nGROUP BY u.id\nORDER BY order_count DESC\nLIMIT 100;\n```",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests SQL optimization with specific query.",
        "primaryDimensions": ["accuracy", "actionability"],
        "tags": ["debugging", "sql", "performance"],
        "source": "custom"
      },
      "response": "This query has several performance bottlenecks. Here's how to fix them:\n\n## Critical Issues\n\n**1. SELECT u.* with GROUP BY forces all columns into GROUP BY**\n\nPostgreSQL requires all non-aggregated columns in SELECT to be in GROUP BY. This creates unnecessary work.\n\n**2. Missing indexes** on `users.created_at` and `orders.user_id`\n\n**3. Computing counts for ALL filtered users** before taking top 100\n\n## Optimizations\n\n### Add indexes first\n```sql\nCREATE INDEX idx_users_created_at ON users(created_at);\nCREATE INDEX idx_orders_user_id ON orders(user_id);\n```\n\n### Rewrite to avoid SELECT *\n```sql\nSELECT u.id, u.email, u.name, -- list only needed columns\n       COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nWHERE u.created_at > '2024-01-01'\nGROUP BY u.id, u.email, u.name -- must match SELECT columns\nORDER BY order_count DESC\nLIMIT 100;\n```\n\n### Use a CTE to separate filtering from counting\n```sql\nWITH filtered_users AS (\n  SELECT id, email, name\n  FROM users\n  WHERE created_at > '2024-01-01'\n)\nSELECT fu.*, COUNT(o.id) as order_count\nFROM filtered_users fu\nLEFT JOIN orders o ON fu.id = o.user_id\nGROUP BY fu.id, fu.email, fu.name\nORDER BY order_count DESC\nLIMIT 100;\n```\n\n### For maximum performance: Materialized counts\nIf order counts don't change frequently, maintain a counter:\n\n```sql\n-- Add column\nALTER TABLE users ADD COLUMN order_count INTEGER DEFAULT 0;\n\n-- Populate\nUPDATE users u\nSET order_count = (SELECT COUNT(*) FROM orders WHERE user_id = u.id);\n\n-- Index it\nCREATE INDEX idx_users_order_count ON users(order_count DESC);\n\n-- Simple query\nSELECT id, email, name, order_count\nFROM users\nWHERE created_at > '2024-01-01'\nORDER BY order_count DESC\nLIMIT 100;\n```\n\nMaintain with a trigger on orders table or periodic updates.\n\n### Verify with EXPLAIN ANALYZE\n```sql\nEXPLAIN ANALYZE [your query];\n```\n\nLook for:\n- Seq Scan → needs index\n- High actual time → bottleneck\n- Rows estimate vs actual → statistics issue (run ANALYZE)\n\n**Expected improvement:** 30s down to <1s with indexes alone. Materialized counts: <100ms.\n\nWhat's your table structure? If orders has 100M+ rows, we might need partitioning or different strategies.",
      "latencyMs": 22228,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 72,
          "reasoning": "Mostly correct general advice (add indexes, avoid SELECT *, use EXPLAIN ANALYZE, consider precomputed counts), but it contains notable inaccuracies/overstatements: PostgreSQL can legally SELECT other user columns while grouping only by u.id if u.id is a primary key (functional dependency), so the “must put all columns in GROUP BY” claim is misleading. The CTE rewrite is unlikely to improve performance (often inlined), and the promised “30s to <1s with indexes alone” is overconfident and not generally guaranteed."
        },
        {
          "dimension": "actionability",
          "score": 86,
          "reasoning": "Provides concrete, runnable next steps (index DDL, query rewrites, EXPLAIN ANALYZE guidance, optional denormalization strategy). Some steps may not actually help (CTE) and one claim may cause unnecessary changes (GROUP BY columns), but overall a user can act on the recommendations without much extra context."
        }
      ],
      "overallScore": 79,
      "timestamp": "2025-12-27T03:26:17.383Z"
    },
    {
      "queryId": "real-009-flaky-test",
      "query": {
        "id": "real-009-flaky-test",
        "query": "Test passes 90% of the time, occasionally fails with timeout. Involves API calls. How to fix this flaky test?",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests flaky test debugging methodology.",
        "primaryDimensions": ["accuracy", "actionability", "completeness"],
        "tags": ["debugging", "testing", "flaky"],
        "source": "custom"
      },
      "response": "Flaky tests with timeouts are usually revealing something real: either the test is coupled to unreliable external state, or there's genuine variability we haven't accounted for.\n\n## Primary Fixes (Pick Based on Test Purpose)\n\n**If this is a unit/integration test:**\n- **Mock the API calls entirely.** Use a library like `nock` (Node), `responses` (Python), or your language's equivalent. Remove the external dependency completely.\n- Why: Unit tests should never touch real networks. 90% success means 10% wasted CI time and developer attention.\n\n**If this must call real APIs:**\n- **Add intelligent retry logic** with exponential backoff for the API calls themselves, not the test. Wrap calls in retry mechanisms that distinguish between retriable errors (timeouts, 429s, 503s) and real failures (400s, 404s).\n- **Increase timeout strategically** - but measure first. Log how long successful calls actually take (p50, p95, p99), then set timeout to p99 + buffer. A blind increase just hides the problem longer.\n\n## Diagnostic Steps\n\n```python\n# Add timing to understand the variance\nimport time\nstart = time.time()\nresponse = api_call()\nduration = time.time() - start\nprint(f\"API call took {duration}s\")\n```\n\nLook for patterns:\n- Does it fail during specific times (rate limiting, peak traffic)?\n- Is it slower in CI than locally (network topology, geographic routing)?\n- Does it correlate with other tests running (resource contention)?\n\n## Structural Solutions\n\n**Contract testing:** Use tools like Pact to verify the API contract separately from integration. Your main test suite uses mocks based on verified contracts.\n\n**Test environment control:** If you control the API, run a local instance or dedicated test environment with guaranteed SLAs.\n\n**Quarantine pattern:** Tag as `@flaky`, run separately, don't block builds. But treat this as temporary—flaky tests are technical debt.\n\nWhat's the test actually validating? That might point us to the right fix. If it's \"does this API response parse correctly,\" that should be mocked. If it's \"does our retry logic work,\" that needs real failure scenarios we can simulate.",
      "latencyMs": 24931,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 93,
          "reasoning": "Recommendations (mocking external APIs for unit tests, measuring/setting timeouts based on percentiles, diagnosing CI/network variance, using contract testing, quarantining flaky tests) are technically sound. Minor caveat: suggesting retries for real API calls is correct in production code but can mask integration-test issues if applied indiscriminately."
        },
        {
          "dimension": "actionability",
          "score": 90,
          "reasoning": "Gives clear, prioritized next steps (mock vs real API path), concrete tactics (retry/backoff conditions, timeout setting method, timing instrumentation), and practical structural options. Could be even more actionable with framework-specific examples (e.g., Jest/Pytest) and explicit guidance on where to place mocks/retries in a test harness."
        },
        {
          "dimension": "completeness",
          "score": 88,
          "reasoning": "Covers main causes and fixes for flaky timeout tests involving APIs, including diagnostics and longer-term solutions. Missing some common flakiness mitigations (test isolation/resource contention mitigation, deterministic scheduling/clock control, better waiting for async conditions vs fixed sleeps, recording/replaying HTTP via VCR-style tools)."
        }
      ],
      "overallScore": 90,
      "timestamp": "2025-12-27T03:26:47.935Z"
    },
    {
      "queryId": "real-010-migration-estimate",
      "query": {
        "id": "real-010-migration-estimate",
        "query": "Estimate migrating 50K line Express.js API to Next.js API routes. 80 endpoints, PostgreSQL with raw queries, 60% test coverage. What factors matter and what's a reasonable range?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests systematic estimation approach.",
        "primaryDimensions": ["completeness", "accuracy", "actionability"],
        "tags": ["estimation", "migration"],
        "source": "custom"
      },
      "response": "# Express → Next.js API Migration Estimate\n\n## Critical Factors\n\n**Architecture coupling** is your biggest variable. Express middleware chains don't map cleanly to Next.js. Each middleware (auth, logging, rate limiting, error handling) needs reimplementation as either:\n- Higher-order functions wrapping route handlers\n- Next.js middleware (edge runtime, limited Node APIs)\n- Inline logic per route\n\n**Raw SQL is actually favorable.** No ORM migration means your queries port directly. The question is whether you'll keep raw queries or adopt Prisma/Drizzle. Adding an ORM adds 30-50% to the database layer effort but pays off long-term.\n\n**Request/Response API differences.** Express's `req.body`, `req.query`, `req.params` patterns differ from Next.js App Router's `request.json()`, `params`, and `searchParams`. Every endpoint needs touch-up, not just copy-paste.\n\n**Test rewriting, not just migration.** Your 60% coverage will need substantial rework. Supertest patterns don't apply; you're now testing with `next/test` utilities or hitting the dev server.\n\n## Effort Breakdown\n\n| Component | Hours (range) | Notes |\n|-----------|---------------|-------|\n| Endpoint migration (80) | 400–600 | Assuming 40% simple, 40% medium, 20% complex |\n| Middleware/infra rebuild | 60–120 | Auth, error handling, logging, CORS |\n| Database layer | 20–60 | Higher if adding ORM |\n| Test migration | 120–200 | Roughly 40% of original test effort |\n| Integration & QA buffer | 20% of above | Edge cases always surface late |\n\n## Realistic Range\n\n| Scenario | Total Hours | Team of 2–3 |\n|----------|-------------|-------------|\n| Clean codebase, experienced team | 700–900 | 2–3 months |\n| Typical conditions | 900–1,200 | 3–5 months |\n| Heavy middleware, tight coupling | 1,200–1,600 | 5–7 months |\n\n## Questions That Sharpen the Estimate\n\n1. **App Router or Pages Router?** App Router is newer but more different from Express patterns.\n2. **How coupled is business logic to Express primitives?** If `req`/`res` flow through your service layer, that's painful.\n3. **Monorepo or separate deployment?** Affects how you can phase the migration.\n4. **Can you run both in parallel?** Incremental migration with a proxy reduces risk but adds coordination overhead.\n\nThe 50K lines matter less than how those lines are organized. A well-structured Express app with thin controllers and separate business logic might migrate in the low range. Express-specific patterns threaded everywhere pushes toward the high end.\n\nWhat's the middleware situation looking like?",
      "latencyMs": 32742,
      "dimensions": [
        {
          "dimension": "completeness",
          "score": 88,
          "reasoning": "Addresses both parts of the query: key factors (middleware coupling, req/res differences, DB layer, tests, deployment strategy) and provides a reasonable effort range with a breakdown. Minor gaps: doesn’t discuss specific Next.js constraints like serverless/timeouts, cold starts, connection pooling to Postgres, or performance/observability impacts which can materially affect migration effort."
        },
        {
          "dimension": "accuracy",
          "score": 74,
          "reasoning": "Generally correct high-level points (middleware mismatch, rewriting wiring, tests needing updates, raw SQL portability). However it conflates “Next.js API routes” with App Router route handlers: classic API routes (pages/api) still use req/res patterns similar to Express, so the stated req.body/request.json differences aren’t universally applicable. Also ‘Supertest patterns don’t apply’ is overstated—Supertest can still be used depending on how the handler/server is exposed."
        },
        {
          "dimension": "actionability",
          "score": 85,
          "reasoning": "Provides actionable estimation structure (component hour ranges, scenarios, and clarifying questions) that a team could use to refine planning. Could be more actionable by adding a concrete migration approach (incremental vs big-bang), a checklist of discovery items, and explicit assumptions about hosting (Vercel vs Node server) and how that affects effort."
        }
      ],
      "overallScore": 82,
      "timestamp": "2025-12-27T03:27:27.310Z"
    },
    {
      "queryId": "real-011-rewrite-decision",
      "query": {
        "id": "real-011-rewrite-decision",
        "query": "Legacy system: 8 years old, no tests, hard to deploy. But it works. Rewrite or incrementally improve? How do we decide?",
        "category": "real-world",
        "difficulty": "expert",
        "rationale": "Tests rewrite vs refactor decision framework.",
        "primaryDimensions": ["completeness", "clarity", "actionability"],
        "tags": ["planning", "rewrite", "architecture"],
        "source": "custom"
      },
      "response": "The honest answer: rewrites fail more often than they succeed, but incremental improvement isn't always possible. The deciding factors aren't technical—they're about what's actually broken and whether you can afford the risk.\n\n**Questions that point toward incremental improvement:**\n\n- Is the pain primarily developer experience (ugly code, slow builds, frustrating deploys)?\n- Can you add tests to the critical paths without major surgery?\n- Is the core architecture sound, just crufty?\n- Does the system actually meet business needs today?\n\nIf yes to most of these, the strangler fig pattern usually wins: wrap the legacy system, add tests at the boundaries, replace pieces gradually. You keep the battle-tested behavior while reducing risk to near zero.\n\n**Questions that point toward rewrite:**\n\n- Has the business fundamentally outgrown what the architecture can support? (e.g., needs multi-tenancy, real-time features, 100x scale)\n- Is the deployment difficulty causing actual business harm—missed SLAs, security vulnerabilities you can't patch, inability to ship?\n- Is the technology stack so obsolete you can't hire or retain engineers?\n- Have you already tried incremental improvement and hit walls?\n\n**The trap to avoid:**\n\nMost rewrites are justified by developer frustration dressed up as business necessity. \"Hard to deploy\" and \"no tests\" are painful but fixable without starting over. The code being ugly isn't a reason—ugly working code has survived 8 years of production. That's evidence of resilience.\n\n**What I'd actually do:**\n\nSpend two weeks adding deployment automation and a handful of integration tests around the scariest parts. If that feels possible, incremental wins. If you hit fundamental blockers (can't containerize, can't test without spinning up the whole world, architecture prevents the changes you need), you have real data for the rewrite conversation.\n\nWhat's the actual pain that's driving this question?",
      "latencyMs": 24781,
      "dimensions": [
        {
          "dimension": "completeness",
          "score": 88,
          "reasoning": "Covers the core decision framework (when to incrementally improve vs rewrite), highlights common traps, and proposes an evidence-gathering approach. Minor gaps: doesn’t discuss budgeting/ROI modeling, team capacity/time horizon, regulatory/compliance constraints, or how to measure success and stop conditions for either path."
        },
        {
          "dimension": "clarity",
          "score": 93,
          "reasoning": "Well-structured with clear sections, bullet-point questions, and a concise recommendation. The narrative is easy to follow and maps directly to the decision being asked."
        },
        {
          "dimension": "actionability",
          "score": 86,
          "reasoning": "Provides concrete next steps (two-week effort on deployment automation + targeted integration tests) and a practical decision heuristic. Could be more immediately actionable with a more detailed checklist (e.g., specific metrics, test strategy examples, deployment hardening steps, and explicit go/no-go criteria for initiating a rewrite)."
        }
      ],
      "overallScore": 89,
      "timestamp": "2025-12-27T03:27:56.766Z"
    },
    {
      "queryId": "real-012-impossible-deadline",
      "query": {
        "id": "real-012-impossible-deadline",
        "query": "VP committed us to a date that's impossible given our velocity. How do I handle this?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests managing unrealistic expectations.",
        "primaryDimensions": ["actionability", "clarity"],
        "tags": ["planning", "communication", "deadline"],
        "source": "custom"
      },
      "response": "This is one of the hardest positions to be in. The commitment's already out there, and now you're holding the bag.\n\n## Your actual options\n\n**1. Escalate immediately with data**\nDocument current velocity, map remaining work, show the math. \"Based on our last 6 sprints averaging X story points and Y scope remaining, we're tracking to Z date. Here's what we'd need to hit the committed date: [specific resources/scope cuts/risk acceptance].\"\n\nThe key: make it their problem to solve, not yours to absorb. You're not saying \"we can't do it\"—you're saying \"here's what it costs.\"\n\n**2. Negotiate scope, not date**\nIf the date is truly immovable (customer contract, board commitment, regulatory), shift to: \"What are we willing to cut or defer?\" Get them to prioritize ruthlessly. MVP the MVP.\n\nThe frame: \"To hit this date with quality we're confident in, here's the feature set we can deliver. Which of these three things matters least?\"\n\n**3. Accept elevated risk explicitly**\nSometimes the answer is: ship it broken, fix it fast. But make them say it. \"We can hit the date if we're comfortable with [specific technical debt/known bugs/reduced testing]. I need explicit sign-off that we're trading quality for speed here.\"\n\nDocument that conversation. Cover your team.\n\n## How to frame the conversation\n\n**Don't say:** \"This is impossible\" or \"You don't understand how development works\"\n- Puts them in defensive mode\n- Makes it about competence rather than constraints\n\n**Do say:** \"Help me understand the constraints that led to this date. Here's what I'm seeing from the delivery side, and I want to make sure we're aligned on what success looks like.\"\n\n**The magic phrase:** \"What problem does this date solve?\" \n\nOften the date itself isn't sacred—there's a customer commitment, a funding milestone, a competitive move. If you understand the *why*, you might find flexibility you didn't know existed.\n\n## The political reality\n\nVPs who commit dates without checking with delivery are either:\n- **Inexperienced** (rare at VP level)\n- **Optimizing for a different game** (winning the deal, looking decisive to the board)\n- **Assuming you'll magically make it work** (most common)\n\nYour job isn't to make them look bad. It's to make the constraints visible before the failure becomes public.\n\nReframe it as: \"I'm trying to protect the commitment you made. Here's what I need to deliver on it.\"\n\n## What to avoid\n\n**Hero culture:** Don't let your team burn out trying to hit an impossible date. The quarter you save isn't worth the engineers you lose.\n\n**Silent failure:** The worst outcome is saying nothing, missing the date, and having it be a surprise. Escalate early, escalate with data.\n\n**Blame:** Don't make this about the VP being stupid. Make it about \"we're all trying to deliver; here's the reality I'm seeing.\"\n\n## The uncomfortable truth\n\nSometimes the answer is: they don't care. The VP needed to win the deal, and your job is to get as close as possible. In that case, your responsibility is to your team: protect them from burnout, document the decisions, and make sure the failure (if it comes) lands on the person who made the commitment, not the people who executed.\n\nWhat's the specific dynamic here? Is this a customer commitment, internal roadmap, funding milestone? That changes which levers you can actually pull.",
      "latencyMs": 34974,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 86,
          "reasoning": "Provides clear, practical paths (escalate with data, negotiate scope, accept risk with sign-off) and concrete talking points/questions. However, it lacks a step-by-step playbook (who to meet first, what artifacts to prepare beyond velocity math), and some advice is context-dependent (e.g., “ship it broken”) without guardrails, so a user may still need minor clarification to execute safely."
        },
        {
          "dimension": "clarity",
          "score": 92,
          "reasoning": "Well-structured with headings, numbered options, do/don’t phrasing, and concise explanations. The flow from options to framing to pitfalls is easy to follow. Slightly wordy in places and a bit opinionated, but overall very readable and organized."
        }
      ],
      "overallScore": 89,
      "timestamp": "2025-12-27T03:28:35.925Z"
    },
    {
      "queryId": "real-013-notification-system",
      "query": {
        "id": "real-013-notification-system",
        "query": "Design a notification system for B2B SaaS: email, in-app, Slack, SMS. Users set preferences per notification type. 10K notifications/day initially. What's the simplest architecture?",
        "category": "real-world",
        "difficulty": "expert",
        "rationale": "Tests simple-first system design.",
        "primaryDimensions": ["actionability", "completeness", "accuracy"],
        "tags": ["system-design", "notifications"],
        "source": "custom"
      },
      "response": "At 10K notifications/day (~7/minute average), we can keep this remarkably simple. Here's the core architecture:\n\n```mermaid\ngraph TB\n    A[API/Event Source] -->|POST /notify| B[Notification Service]\n    B -->|Check preferences| C[(Database)]\n    C -->|User prefs + notification types| B\n    B -->|Filter channels| D{Channel Router}\n    \n    D -->|Email enabled| E[Email Provider<br/>SendGrid/Postmark]\n    D -->|In-app enabled| F[Database<br/>notifications table]\n    D -->|Slack enabled| G[Slack API]\n    D -->|SMS enabled| H[SMS Provider<br/>Twilio]\n    \n    I[Web App] -->|Poll/WebSocket| F\n    \n    style B fill:#e1f5ff\n    style C fill:#fff4e1\n    style D fill:#f0e1ff\n```\n\n## Core Components\n\n**Notification Service** (single service, your language of choice)\n- Receives notification requests with `{user_id, notification_type, content, metadata}`\n- Queries preferences: \"For user X and notification_type Y, which channels are enabled?\"\n- Routes to appropriate channels\n- No queue needed at this scale—synchronous calls are fine\n\n**Database Schema**\n```sql\n-- User preferences\nnotification_preferences (\n  user_id, \n  notification_type,  -- \"invoice_created\", \"team_mention\", etc.\n  email_enabled,\n  in_app_enabled,\n  slack_enabled,\n  sms_enabled\n)\n\n-- In-app notifications storage\nnotifications (\n  id,\n  user_id,\n  notification_type,\n  content,\n  read_at,\n  created_at\n)\n```\n\n**Channel Handlers** (simple functions/classes)\n- **Email**: Direct API call to SendGrid/Postmark\n- **In-app**: INSERT into notifications table\n- **Slack**: Direct API call to Slack webhook or API\n- **SMS**: Direct API call to Twilio\n\n**In-app Delivery**\n- Simple REST endpoint: `GET /notifications?user_id=X&unread=true`\n- Or WebSocket if you want real-time updates\n- Pagination for history\n\n## Simplifications at This Scale\n\n**No message queue needed**: At 7/minute average, direct API calls work fine. If a provider is down, log the failure and retry with exponential backoff (or accept the miss—it's 10K/day, not mission-critical at startup scale).\n\n**No separate worker pool**: Single service handles everything. Scale horizontally if needed (multiple instances behind load balancer).\n\n**No complex routing engine**: Simple if/else based on preference flags. When you hit 100K+/day or need complex rules, *then* consider something like Knock or a rules engine.\n\n**Preference defaults**: Store defaults at the notification type level, with user overrides. Example: \"invoice_created\" defaults to email + in-app, user can toggle off.\n\n## When to Evolve\n\nThis stays simple until:\n- **100K+/day**: Add Redis queue (BullMQ/Sidekiq) for async processing\n- **Complex templating needs**: Add template engine or service like Customer.io\n- **Delivery guarantees matter**: Add persistent queue + retry mechanism\n- **Rich preference logic**: \"Send SMS only for urgent items after 6pm\" → rules engine\n\nStart with the three-table database and a single service. You'll know when you need more. 🎯",
      "latencyMs": 32442,
      "dimensions": [
        {
          "dimension": "actionability",
          "score": 90,
          "reasoning": "Provides a concrete minimal architecture diagram, clear component breakdown, sample DB schema, and specific implementation choices (providers, endpoints). A team could start building from this with minimal additional clarification."
        },
        {
          "dimension": "completeness",
          "score": 85,
          "reasoning": "Addresses the main question (simplest architecture for multi-channel notifications with per-type preferences at 10K/day) and includes evolution guidance. Minor gaps include handling bursts/latency impact of synchronous sends, idempotency/deduplication, provider rate limits, and tenant-level concerns common in B2B SaaS."
        },
        {
          "dimension": "accuracy",
          "score": 83,
          "reasoning": "Generally correct and reasonable for the stated scale. The claim that 'no queue needed' and that synchronous calls are fine can be misleading in real-world scenarios with spikes, slow/failed providers, or UX latency requirements; a lightweight async/job approach is often safer even at 10K/day. Other details (schema, routing concept, channel integrations) are sound."
        }
      ],
      "overallScore": 86,
      "timestamp": "2025-12-27T03:29:15.099Z"
    },
    {
      "queryId": "real-014-rate-limiting",
      "query": {
        "id": "real-014-rate-limiting",
        "query": "Design rate limiting for API: per-user limits, per-endpoint limits, burst allowance. Multiple API servers behind load balancer.",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests distributed rate limiting design.",
        "primaryDimensions": ["accuracy", "completeness", "actionability"],
        "tags": ["system-design", "rate-limiting"],
        "source": "custom"
      },
      "response": "## Rate Limiting Architecture\n\n### Core Design Pattern\n\n**Token Bucket Algorithm** for burst allowance across distributed servers. Each limit dimension (user, endpoint, user+endpoint) maintains independent buckets.\n\n```mermaid\ngraph TB\n    Client[Client Request]\n    LB[Load Balancer]\n    API1[API Server 1]\n    API2[API Server 2]\n    API3[API Server 3]\n    Redis[(Redis Cluster<br/>Centralized State)]\n    \n    Client --> LB\n    LB --> API1\n    LB --> API2\n    LB --> API3\n    \n    API1 <--> Redis\n    API2 <--> Redis\n    API3 <--> Redis\n    \n    Redis -.-> Bucket1[User Bucket<br/>1000/min]\n    Redis -.-> Bucket2[Endpoint Bucket<br/>5000/min]\n    Redis -.-> Bucket3[User+Endpoint<br/>100/min]\n```\n\n### Storage Schema (Redis)\n\n```\n# Token bucket keys\nrl:user:{user_id}:tokens          → current tokens\nrl:user:{user_id}:last_refill     → last refill timestamp\n\nrl:endpoint:{endpoint}:tokens\nrl:endpoint:{endpoint}:last_refill\n\nrl:user_endpoint:{user_id}:{endpoint}:tokens\nrl:user_endpoint:{user_id}:{endpoint}:last_refill\n\n# Configuration (cached from DB)\nrl:config:user:{user_id}          → rate limit config JSON\nrl:config:endpoint:{endpoint}     → endpoint limits\n```\n\n### Rate Limit Configuration\n\n**Three-tier enforcement:**\n\n```typescript\ninterface RateLimitConfig {\n  // Global per-user limits (regardless of endpoint)\n  userLimits: {\n    capacity: 1000,      // bucket size (allows bursts)\n    refillRate: 1000,    // tokens per window\n    window: 60           // seconds\n  },\n  \n  // Per-endpoint limits (all users combined)\n  endpointLimits: {\n    '/api/search': {\n      capacity: 10000,\n      refillRate: 5000,\n      window: 60\n    },\n    '/api/export': {\n      capacity: 100,\n      refillRate: 100,\n      window: 60\n    }\n  },\n  \n  // Per-user-per-endpoint (most restrictive)\n  userEndpointLimits: {\n    '/api/export': {\n      capacity: 20,      // allow burst of 20\n      refillRate: 10,    // but only 10/min sustained\n      window: 60\n    }\n  }\n}\n```\n\n### Token Bucket Algorithm (Lua Script)\n\nExecute atomically in Redis to avoid race conditions across servers:\n\n```lua\n-- token_bucket_consume.lua\nlocal key_tokens = KEYS[1]\nlocal key_last_refill = KEYS[2]\n\nlocal capacity = tonumber(ARGV[1])\nlocal refill_rate = tonumber(ARGV[2])\nlocal window = tonumber(ARGV[3])\nlocal tokens_requested = tonumber(ARGV[4])\nlocal now = tonumber(ARGV[5])\n\n-- Get current state\nlocal tokens = tonumber(redis.call('GET', key_tokens)) or capacity\nlocal last_refill = tonumber(redis.call('GET', key_last_refill)) or now\n\n-- Calculate refill\nlocal elapsed = now - last_refill\nlocal tokens_to_add = (elapsed / window) * refill_rate\ntokens = math.min(capacity, tokens + tokens_to_add)\n\n-- Check if request allowed\nlocal allowed = tokens >= tokens_requested\n\nif allowed then\n    tokens = tokens - tokens_requested\n    redis.call('SET', key_tokens, tokens)\n    redis.call('SET', key_last_refill, now)\n    \n    -- Set expiry to cleanup old buckets\n    redis.call('EXPIRE', key_tokens, window * 2)\n    redis.call('EXPIRE', key_last_refill, window * 2)\n    \n    return {1, math.floor(tokens), math.floor(capacity - tokens)}\nelse\n    return {0, math.floor(tokens), math.floor(capacity - tokens)}\nend\n```\n\n### Middleware Implementation\n\n```python\nfrom typing import Tuple\nimport time\nimport redis\nimport hashlib\n\nclass DistributedRateLimiter:\n    def __init__(self, redis_client):\n        self.redis = redis_client\n        self.lua_script = self._load_lua_script()\n    \n    async def check_rate_limit(\n        self, \n        user_id: str, \n        endpoint: str\n    ) -> Tuple[bool, dict]:\n        \"\"\"\n        Returns: (allowed, headers)\n        Checks all three dimensions: user, endpoint, user+endpoint\n        \"\"\"\n        now = int(time.time())\n        \n        # Check all three limits\n        checks = [\n            self._check_user_limit(user_id, now),\n            self._check_endpoint_limit(endpoint, now),\n            self._check_user_endpoint_limit(user_id, endpoint, now)\n        ]\n        \n        # Most restrictive wins\n        allowed = all(c[0] for c in checks)\n        \n        # Use most restrictive remaining/reset for headers\n        remaining = min(c[1] for c in checks)\n        reset = max(c[2] for c in checks)\n        \n        headers = {\n            'X-RateLimit-Limit': self._get_limit(user_id, endpoint),\n            'X-RateLimit-Remaining': remaining,\n            'X-RateLimit-Reset': reset,\n            'Retry-After': reset - now if not allowed else None\n        }\n        \n        return allowed, headers\n    \n    def _check_user_limit(self, user_id: str, now: int) -> Tuple[bool, int, int]:\n        config = self._get_user_config(user_id)\n        \n        result = self.redis.eval(\n            self.lua_script,\n            2,  # number of keys\n            f\"rl:user:{user_id}:tokens\",\n            f\"rl:user:{user_id}:last_refill\",\n            config['capacity'],\n            config['refillRate'],\n            config['window'],\n            1,  # tokens requested\n            now\n        )\n        \n        allowed, remaining, used = result\n        reset = now + config['window']\n        return (bool(allowed), remaining, reset)\n    \n    def _check_endpoint_limit(self, endpoint: str, now: int):\n        # Similar implementation\n        pass\n    \n    def _check_user_endpoint_limit(self, user_id: str, endpoint: str, now: int):\n        # Similar implementation\n        pass\n```\n\n### Response Headers\n\n```\nHTTP/1.1 200 OK\nX-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 847\nX-RateLimit-Reset: 1703635200\nX-RateLimit-Policy: user=1000/60s; endpoint=5000/60s; user-endpoint=100/60s\n\n# When rate limited:\nHTTP/1.1 429 Too Many Requests\nRetry-After: 42\nX-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 0\nX-RateLimit-Reset: 1703635242\n```\n\n### Critical Considerations\n\n**1. Redis High Availability**\n- Redis Cluster or Sentinel for failover\n- If Redis unavailable: fail open (allow requests) vs fail closed (deny)\n- Circuit breaker pattern to prevent cascading failures\n\n**2. Clock Synchronization**\n- Use Unix timestamps, ensure NTP sync across all API servers\n- Small clock drift acceptable with token bucket (self-correcting)\n\n**3. Performance**\n- Single Redis roundtrip per request (Lua script is atomic)\n- Pipeline multiple limit checks if possible\n- Local cache for configuration (TTL: 60s)\n\n**4. Burst Behavior**\n- `capacity > refillRate` allows bursts\n- Example: capacity=100, refill=50/min\n  - User can burst 100 requests immediately\n  - Then sustained 50/min\n  - Bucket refills continuously, not at window end\n\n**5. Tiered Limits by User Type**\n```python\nUSER_CONFIGS = {\n    'free': {'capacity': 1000, 'refillRate': 1000, 'window': 3600},\n    'pro': {'capacity': 10000, 'refillRate': 10000, 'window': 3600},\n    'enterprise': {'capacity': 100000, 'refillRate': 100000, 'window': 3600}\n}\n```\n\n**6. Monitoring & Alerting**\n```\nMetrics to track:\n- Rate limit hit rate by endpoint/user tier\n- Redis latency P99\n- 429 response rate\n- Tokens remaining distribution (catch too-restrictive limits)\n```\n\n### Alternative: Sliding Window Log\n\nIf you need precise counting over exact time windows:\n\n```lua\n-- Sliding window using sorted set\nlocal key = KEYS[1]\nlocal now = tonumber(ARGV[1])\nlocal window = tonumber(ARGV[2])\nlocal limit = tonumber(ARGV[3])\n\n-- Remove old entries\nredis.call('ZREMRANGEBYSCORE', key, 0, now - window)\n\n-- Count current entries\nlocal current = redis.call('ZCARD', key)\n\nif current < limit then\n    redis.call('ZADD', key, now, now .. ':' .. math.random())\n    redis.call('EXPIRE', key, window)\n    return {1, limit - current - 1}\nelse\n    return {0, 0}\nend\n```\n\n**Token bucket vs sliding window:**\n- Token bucket: better for bursts, more performant, simpler\n- Sliding window: precise time boundaries, more memory per user\n\nFor your needs with burst allowance, **token bucket is the right choice**.\n\nWant to dive deeper into any specific aspect—Redis clustering strategy, specific endpoint configurations, or testing approaches?",
      "latencyMs": 49677,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 78,
          "reasoning": "Overall design choice (token bucket with centralized Redis + Lua atomic updates) is sound for bursty distributed rate limiting. However, there are notable correctness issues: (1) it claims “single Redis roundtrip per request” but actually performs multiple checks (user, endpoint, user+endpoint) which would be multiple Redis calls unless combined; (2) the middleware consumes tokens in each bucket before knowing whether all constraints pass—if a later check fails, earlier buckets have already been decremented (no rollback), causing erroneous throttling; (3) X-RateLimit-Reset/Retry-After are computed as now+window, which is not correct for token bucket semantics (reset depends on refill math / time-to-availability, not fixed windows); (4) remaining/reset aggregation logic is inconsistent (e.g., reset uses max of resets while remaining uses min, but their reset values are simplistic anyway). Minor issues: key schema could be simplified; Lua returns “used” but code treats it as reset-ish elsewhere."
        },
        {
          "dimension": "completeness",
          "score": 92,
          "reasoning": "Addresses per-user limits, per-endpoint limits, per-user-per-endpoint, burst allowance (capacity vs refill), and distributed/multi-server concerns (central state, atomic Lua, HA, clock sync, monitoring). Also offers an alternative approach (sliding window). Main gap: it doesn’t explicitly describe a correct multi-dimension atomic decision/commit strategy (single script to check-and-decrement all buckets together), which is important in real deployments."
        },
        {
          "dimension": "actionability",
          "score": 84,
          "reasoning": "Provides concrete Redis key patterns, a Lua script, middleware skeleton, and operational considerations—enough to implement a working system. But to be safely deployable, the user would need to fix the multi-limit transactional behavior (avoid partial token consumption), correct the reset/retry-after calculations for token bucket, and likely consolidate checks into one Redis call/script for latency and correctness."
        }
      ],
      "overallScore": 85,
      "timestamp": "2025-12-27T03:30:14.730Z"
    },
    {
      "queryId": "real-015-search",
      "query": {
        "id": "real-015-search",
        "query": "Add search to e-commerce site with 1M products. Need: full-text search, filters, faceted navigation, autocomplete. Options and tradeoffs?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests search system design.",
        "primaryDimensions": ["completeness", "accuracy", "actionability"],
        "tags": ["system-design", "search", "ecommerce"],
        "source": "custom"
      },
      "response": "For 1M products with those requirements, we're looking at four serious contenders. Let me break down the tradeoffs:## The Real Tradeoffs\n\n**Elasticsearch** is the industry standard for a reason: maximum flexibility for relevance tuning, boosting, synonyms, and complex queries. The cost is operational complexity. You'll spend time on shard strategy, replica configuration, and fighting garbage collection pauses. Worth it if search is a core differentiator and you have (or will hire) someone who knows the Query DSL deeply.\n\n**Algolia** wins on time-to-value. Their InstantSearch.js library gives you production-ready faceted search UI in hours, not weeks. The pricing model (based on search operations, not just record count) can surprise you at scale though. Run the numbers on your expected query volume.\n\n**Typesense** hits a sweet spot: 80% of Elasticsearch's power at 20% of the operational burden. Single binary, no JVM, built-in high availability. For 1M products, a 3-node cluster handles everything comfortably. This is my recommendation if you want control without complexity.\n\n**Meilisearch** optimizes for \"just works\" defaults. Less tuning surface area than Typesense, which is a feature if you don't want to tune. Federating searches across multiple indices is still maturing compared to the others.\n\n## Architecture Considerations\n\nWhichever you choose:\n\n1. **Sync strategy matters.** Build your product→search pipeline with change data capture (Debezium) or event-driven updates, not batch reindexing. Stale search results kill conversion.\n\n2. **Facets need denormalization.** Store computed fields (price ranges, rating buckets, \"in stock\" boolean) directly in the search index rather than computing at query time.\n\n3. **Autocomplete is two things:** prefix matching (what they're typing now) and query suggestions (what others searched). Most engines handle the first natively; the second needs analytics piped back in.\n\nWhat's your current stack and ops capacity? That'll sharpen the recommendation.",
      "latencyMs": 41155,
      "dimensions": [
        {
          "dimension": "completeness",
          "score": 82,
          "reasoning": "Covers the core requirements (full-text, filters/facets, autocomplete) and compares several relevant options with clear tradeoffs plus key architectural considerations. Minor gaps: omits common alternatives (OpenSearch/Solr/managed offerings), deeper discussion of scaling/cost modeling, security/permissions, multi-region/SLA, and implementation details for faceting/relevance."
        },
        {
          "dimension": "accuracy",
          "score": 83,
          "reasoning": "Most statements are broadly correct (ES flexibility vs ops burden, Algolia time-to-value/pricing sensitivity, autocomplete split, denormalization for facets). Some claims are a bit assertive without qualifiers (e.g., a 3-node Typesense cluster 'handles everything comfortably' depends heavily on QPS, hardware, indexing rate, and feature use). No major factual errors."
        },
        {
          "dimension": "actionability",
          "score": 78,
          "reasoning": "Provides actionable direction (which tools to consider, what to evaluate, CDC/event-driven sync, denormalized facet fields, separating prefix vs suggestion). However, it lacks concrete next steps like a decision checklist, sizing guidance, indexing schema examples, rollout plan, and how to measure relevance/latency/cost—so a user would still need follow-up work to execute."
        }
      ],
      "overallScore": 81,
      "timestamp": "2025-12-27T03:31:02.739Z"
    },
    {
      "queryId": "real-016-multi-tenant",
      "query": {
        "id": "real-016-multi-tenant",
        "query": "Building multi-tenant SaaS. Database options: shared, schema-per-tenant, database-per-tenant. When to choose each?",
        "category": "real-world",
        "difficulty": "hard",
        "rationale": "Tests multi-tenancy architecture tradeoffs.",
        "primaryDimensions": ["completeness", "accuracy", "actionability"],
        "tags": ["system-design", "multi-tenant", "database"],
        "source": "custom"
      },
      "response": "## Decision Framework\n\n**Choose Shared Database when:**\n- Supporting hundreds to millions of small tenants\n- Standardized feature set across all customers\n- Cost per tenant must be minimal (freemium, low-price tiers)\n- Team size is small, operational overhead must stay low\n- Example: Notion, Slack (for smaller teams), most B2C SaaS\n\n**Choose Schema-Per-Tenant when:**\n- 50-5000 mid-market B2B customers\n- Need per-tenant customization (custom fields, table extensions)\n- Want isolation benefits without full database overhead\n- Planning to offer tiered pricing with custom features\n- Example: Many vertical SaaS platforms, CRMs, project management tools\n\n**Choose Database-Per-Tenant when:**\n- Serving enterprise customers paying $50k+ annually\n- Hard compliance requirements (HIPAA, SOC 2, data residency laws)\n- Customers demand dedicated resources in SLAs\n- Need to offer different database versions per tenant\n- White-label scenarios where tenants feel like separate products\n- Example: Enterprise healthcare platforms, financial services SaaS, large-scale ERPs\n\n## Hybrid Approach\n\nMany successful SaaS products start with shared database and graduate high-value customers to dedicated databases. Stripe does this: smaller merchants share infrastructure, large enterprise customers get dedicated resources. Build the abstraction layer early so you can migrate tenants between models as they grow.\n\nWhat's your target customer profile and expected tenant count?",
      "latencyMs": 34137,
      "dimensions": [
        {
          "dimension": "completeness",
          "score": 82,
          "reasoning": "Covers all three models with clear selection criteria and mentions a hybrid migration strategy. However, it omits several important decision factors (e.g., backup/restore and DR per-tenant, noisy-neighbor mitigation, query/analytics implications, indexing/migration complexity, operational tooling, security boundaries) and doesn’t explicitly contrast pros/cons for each option."
        },
        {
          "dimension": "accuracy",
          "score": 78,
          "reasoning": "Most guidance is broadly correct (cost vs isolation trade-offs, enterprise/compliance pushing toward more isolation). Some statements are oversimplified or potentially misleading: compliance doesn’t always require database-per-tenant; schema-per-tenant doesn’t inherently enable easy custom table extensions; and the specific company examples (Notion/Slack/Stripe behavior) are not reliably substantiated and may be inaccurate or context-dependent."
        },
        {
          "dimension": "actionability",
          "score": 80,
          "reasoning": "Provides actionable heuristics (tenant count ranges, pricing tiers, compliance/isolation needs) and suggests building an abstraction layer for migrations. Still lacks concrete next steps like a checklist, decision matrix, or implementation considerations (tenant ID strategy, connection pooling limits, migration/automation approach), so users may need additional guidance to execute."
        }
      ],
      "overallScore": 80,
      "timestamp": "2025-12-27T03:31:43.170Z"
    },
    {
      "queryId": "real-017-review-react",
      "query": {
        "id": "real-017-review-react",
        "query": "Review this React component:\n\n```jsx\nfunction SearchResults() {\n  const [query, setQuery] = useState('');\n  const [results, setResults] = useState([]);\n  useEffect(() => {\n    fetch(`/api/search?q=${query}`)\n      .then(r => r.json())\n      .then(setResults);\n  }, [query]);\n  return (\n    <div>\n      <input value={query} onChange={e => setQuery(e.target.value)} />\n      {results.map(r => <div>{r.title}</div>)}\n    </div>\n  );\n}\n```",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests identifying issues (debounce, key, error handling).",
        "primaryDimensions": ["accuracy", "completeness"],
        "tags": ["code-review", "react"],
        "source": "custom"
      },
      "response": "This component has several critical issues that'll cause problems in production:\n\n## Critical Issues\n\n**Race Condition**\nFetch requests can complete out of order. If someone types \"react\" then quickly changes to \"vue\", the slower \"react\" response might arrive last and overwrite the \"vue\" results. Need request cancellation.\n\n**API Hammering**\nFires a request on every keystroke. Type \"javascript\" = 10 requests. Needs debouncing (300-500ms is standard).\n\n**Missing Error Handling**\nNetwork failures will silently break the component. No error state means users sit staring at stale results.\n\n**Empty Query Behavior**\nRuns `fetch('/api/search?q=')` immediately on mount with an empty string. Likely wasteful or returns garbage.\n\n## Secondary Issues\n\n- **No loading state**: Users don't know if it's searching or done\n- **Missing keys**: `.map(r => <div>{r.title}</div>)` lacks key prop for React reconciliation\n- **No null safety**: If API returns null/undefined for results, `.map()` will explode\n\n## Fix Pattern\n\n```jsx\nfunction SearchResults() {\n  const [query, setQuery] = useState('');\n  const [results, setResults] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  useEffect(() => {\n    if (!query.trim()) {\n      setResults([]);\n      return;\n    }\n\n    const controller = new AbortController();\n    const timeoutId = setTimeout(async () => {\n      setLoading(true);\n      setError(null);\n      \n      try {\n        const res = await fetch(`/api/search?q=${encodeURIComponent(query)}`, {\n          signal: controller.signal\n        });\n        if (!res.ok) throw new Error('Search failed');\n        const data = await res.json();\n        setResults(data);\n      } catch (e) {\n        if (e.name !== 'AbortError') {\n          setError(e.message);\n        }\n      } finally {\n        setLoading(false);\n      }\n    }, 300);\n\n    return () => {\n      clearTimeout(timeoutId);\n      controller.abort();\n    };\n  }, [query]);\n\n  return (\n    <div>\n      <input value={query} onChange={e => setQuery(e.target.value)} />\n      {loading && <div>Searching...</div>}\n      {error && <div>Error: {error}</div>}\n      {results.map(r => <div key={r.id}>{r.title}</div>)}\n    </div>\n  );\n}\n```\n\nThe abort controller cancels in-flight requests, the timeout debounces input, and proper state management gives users feedback. Also added URL encoding for the query parameter—without it, searches with spaces or special characters will break.",
      "latencyMs": 24049,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 92,
          "reasoning": "Identifies real issues: out-of-order responses (race condition), request-per-keystroke, missing error/loading states, missing React keys, and lack of URL encoding. Proposed AbortController + debounce pattern is broadly correct and commonly used. Minor caveats: assumes API returns an array and that each item has `id` for keys; the stated “null safety” issue is possible but not inherent unless the API misbehaves."
        },
        {
          "dimension": "completeness",
          "score": 90,
          "reasoning": "Thorough review covering the main production concerns and provides a concrete improved implementation (debounce, cancellation, loading/error UI, empty-query handling, keys, encoding). Minor omissions include discussing React Strict Mode double-invocation in dev, accessibility considerations, or validating/normalizing API response shape, but these are not essential to the core review."
        }
      ],
      "overallScore": 91,
      "timestamp": "2025-12-27T03:32:12.535Z"
    },
    {
      "queryId": "real-018-review-api",
      "query": {
        "id": "real-018-review-api",
        "query": "Review this API endpoint:\n\n```typescript\napp.post('/api/users', async (req, res) => {\n  const { email, password, role } = req.body;\n  const hashedPassword = await bcrypt.hash(password, 10);\n  const user = await db.user.create({\n    data: { email, password: hashedPassword, role }\n  });\n  res.json({ user });\n});\n```",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests identifying security issues.",
        "primaryDimensions": ["accuracy", "completeness"],
        "tags": ["code-review", "security", "api"],
        "source": "custom"
      },
      "response": "This endpoint has several critical security vulnerabilities:\n\n## 🚨 Critical Issues\n\n**1. Role Injection / Privilege Escalation**\nAnyone can register as an admin by sending `\"role\": \"admin\"` in the request body. Never accept role assignments from user input.\n\n**2. Missing Authentication/Authorization**\nNo check on who can create users. In most apps, only admins should create users, or registration should be public but locked to a default role.\n\n**3. Sensitive Data Exposure**\nReturns the entire user object including `hashedPassword`. Even hashed, this shouldn't be exposed.\n\n**4. Zero Input Validation**\nNo checks for:\n- Valid email format\n- Password strength/length\n- Whether email already exists\n- Required fields presence\n\n**5. No Error Handling**\nDatabase or bcrypt failures will crash the server and leak stack traces.\n\n## Hardened Version\n\n```typescript\napp.post('/api/users', async (req, res) => {\n  try {\n    const { email, password } = req.body;\n    \n    // Input validation\n    if (!email || !password) {\n      return res.status(400).json({ error: 'Email and password required' });\n    }\n    \n    if (!/^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(email)) {\n      return res.status(400).json({ error: 'Invalid email format' });\n    }\n    \n    if (password.length < 8) {\n      return res.status(400).json({ error: 'Password must be at least 8 characters' });\n    }\n    \n    // Check for existing user\n    const existing = await db.user.findUnique({ where: { email } });\n    if (existing) {\n      return res.status(409).json({ error: 'Email already registered' });\n    }\n    \n    const hashedPassword = await bcrypt.hash(password, 10);\n    \n    // Force default role, never trust client input\n    const user = await db.user.create({\n      data: { \n        email, \n        password: hashedPassword, \n        role: 'USER' // Hardcoded, not from request\n      }\n    });\n    \n    // Return only safe fields\n    res.status(201).json({ \n      user: {\n        id: user.id,\n        email: user.email,\n        role: user.role\n      }\n    });\n    \n  } catch (error) {\n    console.error('User creation failed:', error);\n    res.status(500).json({ error: 'Failed to create user' });\n  }\n});\n```\n\n## Additional Recommendations\n\n- **Use a validation library** (Zod, Joi, express-validator) instead of manual checks\n- **Add rate limiting** to prevent spam registrations\n- **Consider email verification** before account activation\n- **Use prepared statements/parameterized queries** (Prisma handles this, but good to verify)\n- **Add request size limits** to prevent payload attacks\n- **Implement CSRF protection** if using cookies for auth\n\nThe original code would earn a critical severity rating in any security audit. The role injection alone is a direct path to complete system compromise.",
      "latencyMs": 22343,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 92,
          "reasoning": "Identifies real issues: client-controlled role enables privilege escalation, returning the created user can expose hashed passwords, lack of validation/uniqueness checks, and missing error handling. Minor overstatement: unhandled async errors may crash or may be handled depending on Express version/error middleware, and “leak stack traces” isn’t guaranteed unless errors are surfaced to clients."
        },
        {
          "dimension": "completeness",
          "score": 90,
          "reasoning": "Covers the major security and correctness concerns and provides a safer rewritten endpoint plus practical additional recommendations (validation libs, rate limiting, email verification, CSRF considerations). Could be slightly more complete by mentioning password policy nuances (breach checks), audit logging, and distinguishing public signup vs admin user-creation flows, but overall thorough."
        }
      ],
      "overallScore": 91,
      "timestamp": "2025-12-27T03:32:39.587Z"
    },
    {
      "queryId": "real-019-review-sql",
      "query": {
        "id": "real-019-review-sql",
        "query": "Review this database query:\n\n```typescript\nconst userId = req.params.id;\nconst query = `SELECT * FROM users WHERE id = ${userId}`;\nconst result = await db.query(query);\n```",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests identifying SQL injection vulnerability.",
        "primaryDimensions": ["accuracy", "clarity"],
        "tags": ["code-review", "security", "sql"],
        "source": "custom"
      },
      "response": "## Critical Vulnerability: SQL Injection 🚨\n\nThis code is **dangerous**. The userId is directly interpolated into the SQL query string, creating a classic SQL injection vulnerability.\n\n### The Attack\n\nAn attacker could send:\n```\nGET /users/1 OR 1=1--\n```\n\nThis transforms your query into:\n```sql\nSELECT * FROM users WHERE id = 1 OR 1=1--\n```\n\nThat returns **all users**. Worse attacks could delete data, exfiltrate information, or compromise the entire database.\n\n### The Fix\n\nUse **parameterized queries** (prepared statements):\n\n```typescript\nconst userId = req.params.id;\nconst query = 'SELECT * FROM users WHERE id = $1';\nconst result = await db.query(query, [userId]);\n```\n\nThe database now treats `userId` as **data**, not executable code. The SQL engine handles escaping automatically.\n\n### Additional Improvements\n\n```typescript\n// Validate input\nconst userId = parseInt(req.params.id, 10);\nif (isNaN(userId)) {\n  return res.status(400).json({ error: 'Invalid user ID' });\n}\n\n// Specify columns (performance + security)\nconst query = 'SELECT id, name, email, created_at FROM users WHERE id = $1';\nconst result = await db.query(query, [userId]);\n\n// Handle not found\nif (result.rows.length === 0) {\n  return res.status(404).json({ error: 'User not found' });\n}\n```\n\n**Never concatenate user input into SQL strings.** This applies to every database query in your codebase.",
      "latencyMs": 15198,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 92,
          "reasoning": "Correctly identifies SQL injection risk from string interpolation and recommends parameterized queries. Example attack and explanation are valid, though the $1 placeholder is Postgres-specific (other DBs use ?), and parseInt validation may be inappropriate if IDs are UUIDs/strings. These are minor context assumptions."
        },
        {
          "dimension": "clarity",
          "score": 95,
          "reasoning": "Well-structured with clear sections (vulnerability, attack, fix, improvements) and readable code snippets. The progression is easy to follow and directly answers the query review; minor stylistic noise (emoji) doesn’t materially reduce clarity."
        }
      ],
      "overallScore": 94,
      "timestamp": "2025-12-27T03:33:00.218Z"
    },
    {
      "queryId": "real-020-review-auth",
      "query": {
        "id": "real-020-review-auth",
        "query": "Review this auth middleware:\n\n```typescript\nconst authMiddleware = (req, res, next) => {\n  const token = req.headers.authorization;\n  if (token) {\n    const decoded = jwt.decode(token);\n    req.user = decoded;\n    next();\n  } else {\n    res.status(401).json({ error: 'No token' });\n  }\n};\n```",
        "category": "real-world",
        "difficulty": "standard",
        "rationale": "Tests identifying jwt.decode vs jwt.verify issue.",
        "primaryDimensions": ["accuracy", "clarity"],
        "tags": ["code-review", "security", "auth"],
        "source": "custom"
      },
      "response": "This middleware has **critical security vulnerabilities** that would allow anyone to authenticate as any user. Here's what's broken:\n\n## Critical Issues\n\n**1. Using `jwt.decode()` instead of `jwt.verify()`**\n- `decode()` just base64-decodes the JWT without verifying the signature\n- Anyone can craft a token with `{ userId: 'admin' }` and gain access\n- This completely bypasses authentication\n\n**2. Missing Bearer prefix extraction**\n- Authorization headers are typically `\"Bearer <token>\"`\n- Code tries to decode the entire header string\n\n**3. No error handling**\n- Malformed tokens will crash the application\n- No graceful degradation\n\n**4. No validation of decoded payload**\n- Doesn't check if user data exists or is valid\n\n## Secure Implementation\n\n```typescript\nconst authMiddleware = (req, res, next) => {\n  try {\n    const authHeader = req.headers.authorization;\n    \n    if (!authHeader?.startsWith('Bearer ')) {\n      return res.status(401).json({ error: 'Invalid authorization format' });\n    }\n\n    const token = authHeader.slice(7); // Remove 'Bearer '\n    \n    // CRITICAL: Use verify() with your secret key\n    const decoded = jwt.verify(token, process.env.JWT_SECRET);\n    \n    if (!decoded || !decoded.userId) {\n      return res.status(401).json({ error: 'Invalid token payload' });\n    }\n    \n    req.user = decoded;\n    next();\n    \n  } catch (err) {\n    if (err.name === 'TokenExpiredError') {\n      return res.status(401).json({ error: 'Token expired' });\n    }\n    if (err.name === 'JsonWebTokenError') {\n      return res.status(401).json({ error: 'Invalid token' });\n    }\n    return res.status(500).json({ error: 'Authentication error' });\n  }\n};\n```\n\n## Additional Considerations\n\n- **Algorithm whitelist**: Specify allowed algorithms in `jwt.verify()` options: `{ algorithms: ['HS256'] }` to prevent algorithm confusion attacks\n- **Token rotation**: Implement refresh tokens for better security\n- **Rate limiting**: Add rate limiting to prevent brute force attempts\n- **Logging**: Log failed authentication attempts for monitoring\n\nThe original code would fail any security audit. The fix above provides cryptographic verification that makes authentication actually secure.",
      "latencyMs": 19509,
      "dimensions": [
        {
          "dimension": "accuracy",
          "score": 88,
          "reasoning": "Correctly identifies the core flaw: jwt.decode() does not verify signatures (auth bypass), and correctly notes missing Bearer token parsing and lack of payload validation. The proposed fix using jwt.verify() with error handling and optional algorithm whitelisting is appropriate. Minor overstatement: jwt.decode() typically returns null on malformed tokens rather than crashing the app, so the \"will crash\" claim is not strictly accurate."
        },
        {
          "dimension": "clarity",
          "score": 94,
          "reasoning": "Well-structured, easy to follow, with clear headings, bullet points, and a concrete improved implementation. The explanations map directly to the code problems and the fix, with actionable additional considerations."
        }
      ],
      "overallScore": 91,
      "timestamp": "2025-12-27T03:33:29.093Z"
    }
  ]
}
